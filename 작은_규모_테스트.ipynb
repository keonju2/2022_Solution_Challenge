{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "작은 규모 테스트.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jP7L9ntd0Wsf",
        "outputId": "f53bd474-e193-41d4-a8b0-5024180afe32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3Ch4ycc0RtZ",
        "outputId": "4b1864f9-3252-4a8d-a87c-416641707370"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 10876, done.\u001b[K\n",
            "remote: Total 10876 (delta 0), reused 0 (delta 0), pack-reused 10876\u001b[K\n",
            "Receiving objects: 100% (10876/10876), 11.02 MiB | 24.58 MiB/s, done.\n",
            "Resolving deltas: 100% (7510/7510), done.\n",
            "/content/yolov5\n",
            "\u001b[K     |████████████████████████████████| 596 kB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 7.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 178 kB 46.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 145 kB 45.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 138 kB 50.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.5 MB/s \n",
            "\u001b[?25h  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Setup complete. Using torch 1.10.0+cu111 (Tesla K80)\n"
          ]
        }
      ],
      "source": [
        "#clone YOLOv5 and \n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "!pip install -qr requirements.txt # install dependencies\n",
        "!pip install -q roboflow\n",
        "\n",
        "import torch\n",
        "import os\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/gdrive/MyDrive/custom_dataset.zip'  > /dev/null -d '/content/yolov5/custom_dataset'"
      ],
      "metadata": {
        "id": "T8jc8cVhmdrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import requests\n",
        "import yaml\n",
        "from PIL import Image\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "7_vgJhKLxZ9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_txt(file):\n",
        "  names = []\n",
        "  file = Path(file)\n",
        "\n",
        "\n",
        "  with open(file) as f:  #load json\n",
        "        json_data = json.load(f) \n",
        "\n",
        "\n",
        "  for data in json_data: \n",
        "      if data == 'ObjectInfo':\n",
        "        lxtl, lytl, lxbr, lybr = json_data[data]['BoundingBox']['Leye']['Position']\n",
        "        rxtl, rytl, rxbr, rybr = json_data[data]['BoundingBox']['Reye']['Position']\n",
        "        # xtl, ytl, xbr, ybr : x상, y상, x하, y하\n",
        "\n",
        "      if data == 'FileInfo':\n",
        "        file_width = json_data[data]['Width']\n",
        "        file_height = json_data[data]['Height']\n",
        "\n",
        "  lxtl=float(lxtl)\n",
        "  lytl=float(lytl)\n",
        "  lxbr=float(lxbr)\n",
        "  lybr=float(lybr)\n",
        "  rxtl=float(rxtl)\n",
        "  rytl=float(rytl)\n",
        "  rxbr=float(rxbr)\n",
        "  rybr=float(rybr)\n",
        "  file_width=float(file_width)\n",
        "  file_height=float(file_height)\n",
        "  \n",
        "\n",
        "\n",
        "  # 좌표 구하기\n",
        "  l_width = lxbr - lxtl\n",
        "  l_height = lybr - lytl\n",
        "  l_center_x = (lxbr + lxtl)/2\n",
        "  l_center_y = (lybr + lytl)/2\n",
        "\n",
        "  r_width = rxbr - rxtl\n",
        "  r_height = rybr - rytl\n",
        "  r_center_x = (rxbr + rxtl)/2\n",
        "  r_center_y = (rybr + rytl)/2\n",
        "\n",
        "  f_dw = 1./file_width\n",
        "  f_dh = 1./file_height\n",
        "\n",
        "  l_x = l_center_x * f_dw\n",
        "  l_y = l_center_y * f_dh\n",
        "  l_w = l_width * f_dw\n",
        "  l_h = l_height * f_dh\n",
        "\n",
        "  r_x = r_center_x * f_dw\n",
        "  r_y = r_center_y * f_dh\n",
        "  r_w = r_width * f_dw\n",
        "  r_h = r_height * f_dh\n",
        "\n",
        "  l_box = ['0', str(l_x), str(l_y), str(l_w), str(l_h)]\n",
        "  r_box = ['1', str(r_x), str(r_y), str(r_w), str(r_h)]\n",
        "\n",
        "  return l_box, r_box"
      ],
      "metadata": {
        "id": "hp7YzvrooJ0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_txt('/content/yolov5/custom_dataset/test/label/R_071_30_M_01_M0_G1_C0_01.json')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ag2O74U1yGmq",
        "outputId": "b30d525e-57d1-4a4e-d1bd-95f009ab343e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['0',\n",
              "  '0.39381249999999995',\n",
              "  '0.51410546875',\n",
              "  '0.06968055555555558',\n",
              "  '0.015226562500000007'],\n",
              " ['1',\n",
              "  '0.5667152777777777',\n",
              "  '0.49976171875',\n",
              "  '0.07390277777777775',\n",
              "  '0.015117187500000018'])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_dir='/content/yolov5/custom_dataset/test/label'\n",
        "file_list = os.listdir(path_dir)\n",
        "\n",
        "for i in range(len(file_list)):\n",
        "  file_name = path_dir + '/' + file_list[i]\n",
        "  if os.path.splitext(file_name)[1] == '.json':\n",
        "    l_b, r_b = make_txt(file_name)\n",
        "    new_file = file_name.replace('.json','')\n",
        "    f = open(new_file+'.txt','w')\n",
        "    f.write(' '.join(l_b))\n",
        "    f.write('\\n')\n",
        "    f.write(' '.join(r_b))\n",
        "    f.close()"
      ],
      "metadata": {
        "id": "vCYoilhp_Gpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_dir='/content/yolov5/custom_dataset/train/label'\n",
        "file_list = os.listdir(path_dir)\n",
        "\n",
        "for i in range(len(file_list)):\n",
        "  file_name = path_dir + '/' + file_list[i]\n",
        "  if os.path.splitext(file_name)[1] == '.json':\n",
        "    l_b, r_b = make_txt(file_name)\n",
        "    new_file = file_name.replace('.json','')\n",
        "    f = open(new_file+'.txt','w')\n",
        "    f.write(' '.join(l_b))\n",
        "    f.write('\\n')\n",
        "    f.write(' '.join(r_b))\n",
        "    f.close()"
      ],
      "metadata": {
        "id": "xWgD3cziIiHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_dir='/content/yolov5/custom_dataset/valid/label'\n",
        "file_list = os.listdir(path_dir)\n",
        "\n",
        "for i in range(len(file_list)):\n",
        "  file_name = path_dir + '/' + file_list[i]\n",
        "  if os.path.splitext(file_name)[1] == '.json':\n",
        "    l_b, r_b = make_txt(file_name)\n",
        "    new_file = file_name.replace('.json','')\n",
        "    f = open(new_file+'.txt','w')\n",
        "    f.write(' '.join(l_b))\n",
        "    f.write('\\n')\n",
        "    f.write(' '.join(r_b))\n",
        "    f.close()"
      ],
      "metadata": {
        "id": "khbQoXEcIkmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " from glob import glob"
      ],
      "metadata": {
        "id": "lc6GqWvtQsDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[os.remove(f) for f in glob(\"/content/yolov5/custom_dataset/test/label/*.json\")]\n",
        "[os.remove(f) for f in glob(\"/content/yolov5/custom_dataset/train/label/*.json\")]\n",
        "[os.remove(f) for f in glob(\"/content/yolov5/custom_dataset/valid/label/*.json\")]"
      ],
      "metadata": {
        "id": "ywpvUJCIQa-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "make_yaml = {\n",
        "             \"train\" : \"/content/yolov5/custom_dataset/train\",\n",
        "             \"val\": \"/content/yolov5/custom_dataset/valid\",\n",
        "            \"test\": \"/content/yolov5/custom_dataset/test\",\n",
        "             \"nc\" : 2,\n",
        "             \"names\": [\"left_eye\", \"right_eye\"]\n",
        "}\n",
        "with open('/content/yolov5/data/custom_dataset.yaml', 'w') as outfile:\n",
        "    yaml.dump(make_yaml, outfile, default_flow_style=False)"
      ],
      "metadata": {
        "id": "rl-JaxHmigb-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 640 --batch 16 --epochs 3 --data /content/yolov5/data/custom_dataset.yaml --weights yolov5s.pt --cache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORd_XqZkKGOb",
        "outputId": "053af1d5-d273-4d32-f0ce-bc40b3611031"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/yolov5/data/custom_dataset.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=3, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v6.0-255-gca0a007 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model Summary: 270 layers, 7025023 parameters, 7025023 gradients, 15.9 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/yolov5/custom_dataset/train/labels' images and labels...400 found, 0 missing, 0 empty, 0 corrupt: 100% 400/400 [00:00<00:00, 1429.13it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov5/custom_dataset/train/labels.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.3GB ram): 100% 400/400 [00:04<00:00, 97.09it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5/custom_dataset/valid/labels' images and labels...400 found, 0 missing, 0 empty, 0 corrupt: 100% 400/400 [00:00<00:00, 665.16it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov5/custom_dataset/valid/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.3GB ram): 100% 400/400 [00:04<00:00, 89.57it/s]\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.72 anchors/target, 0.998 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       0/2     3.22G    0.1183   0.03139   0.02776        46       640: 100% 25/25 [00:30<00:00,  1.22s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 13/13 [00:08<00:00,  1.62it/s]\n",
            "                 all        400          0          0          0          0          0\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       1/2     3.48G    0.1107   0.03006   0.02643        55       640: 100% 25/25 [00:28<00:00,  1.15s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 13/13 [00:07<00:00,  1.79it/s]\n",
            "                 all        400          0          0          0          0          0\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       2/2     3.48G    0.1006   0.02974   0.02431        51       640: 100% 25/25 [00:28<00:00,  1.15s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 13/13 [00:06<00:00,  1.89it/s]\n",
            "                 all        400        800    9.8e-06    0.00125   4.11e-06   1.64e-06\n",
            "\n",
            "3 epochs completed in 0.031 hours.\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 14.4MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 14.4MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model Summary: 213 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 13/13 [00:09<00:00,  1.39it/s]\n",
            "                 all        400        800    9.8e-06    0.00125   4.11e-06   1.64e-06\n",
            "            left_eye        400        400   1.96e-05     0.0025   8.22e-06   3.29e-06\n",
            "           right_eye        400        400          0          0          0          0\n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/yolov5/export.py --weights /content/yolov5/runs/train/exp/weights/best.pt --img 640 --batch 16"
      ],
      "metadata": {
        "id": "lKtWL8_mX9GL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c186903f-3580-44e9-eb15-5b1ad38918f1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mexport: \u001b[0mdata=data/coco128.yaml, weights=['/content/yolov5/runs/train/exp/weights/best.pt'], imgsz=[640], batch_size=16, device=cpu, half=False, inplace=False, train=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=12, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['torchscript', 'onnx']\n",
            "YOLOv5 🚀 v6.0-255-gca0a007 torch 1.10.0+cu111 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 213 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from /content/yolov5/runs/train/exp/weights/best.pt with output shape (16, 25200, 7) (14.4 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 1.10.0+cu111...\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success, saved as /content/yolov5/runs/train/exp/weights/best.torchscript (28.5 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m onnx not found and is required by YOLOv5, attempting auto-update...\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.10.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (12.7 MB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.10.0.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx) (3.17.3)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.10.2\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per ['onnx']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.10.2...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success, saved as /content/yolov5/runs/train/exp/weights/best.onnx (28.5 MB)\n",
            "\n",
            "Export complete (66.39s)\n",
            "Results saved to \u001b[1m/content/yolov5/runs/train/exp/weights\u001b[0m\n",
            "Detect:          python detect.py --weights /content/yolov5/runs/train/exp/weights/best.onnx\n",
            "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', '/content/yolov5/runs/train/exp/weights/best.onnx')\n",
            "Validate:        python val.py --weights /content/yolov5/runs/train/exp/weights/best.onnx\n",
            "Visualize:       https://netron.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install onnx_tf"
      ],
      "metadata": {
        "id": "3Y6xfOO5YvtN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18ae78f6-f9e2-4eef-ceb2-55fd5fc4f098"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx_tf\n",
            "  Downloading onnx_tf-1.9.0-py3-none-any.whl (222 kB)\n",
            "\u001b[K     |████████████████████████████████| 222 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 41.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: onnx>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from onnx_tf) (1.10.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from onnx_tf) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.9.0->onnx_tf) (3.10.0.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx>=1.9.0->onnx_tf) (3.17.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx>=1.9.0->onnx_tf) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.9.0->onnx_tf) (1.19.5)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->onnx_tf) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons, onnx-tf\n",
            "Successfully installed onnx-tf-1.9.0 tensorflow-addons-0.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/yolov5/models/tf.py --weights /content/yolov5/runs/train/exp/weights/best.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3U9e8n_9p2N7",
        "outputId": "78868505-9199-4a86-feaa-baf59f2a3845"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtf: \u001b[0mweights=/content/yolov5/runs/train/exp/weights/best.pt, imgsz=[640, 640], batch_size=1, dynamic=False\n",
            "Model Summary: 270 layers, 7025023 parameters, 0 gradients, 15.9 GFLOPs\n",
            "2022-02-15 09:15:27.789310: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  1    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512], [640, 640]]\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(1, 640, 640, 3)]   0           []                               \n",
            "                                                                                                  \n",
            " tf_conv (TFConv)               (1, 320, 320, 32)    3584        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " tf_conv_1 (TFConv)             (1, 160, 160, 64)    18688       ['tf_conv[0][0]']                \n",
            "                                                                                                  \n",
            " tfc3 (TFC3)                    (1, 160, 160, 64)    19200       ['tf_conv_1[0][0]']              \n",
            "                                                                                                  \n",
            " tf_conv_7 (TFConv)             (1, 80, 80, 128)     74240       ['tfc3[0][0]']                   \n",
            "                                                                                                  \n",
            " tfc3_1 (TFC3)                  (1, 80, 80, 128)     116736      ['tf_conv_7[0][0]']              \n",
            "                                                                                                  \n",
            " tf_conv_15 (TFConv)            (1, 40, 40, 256)     295936      ['tfc3_1[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_2 (TFC3)                  (1, 40, 40, 256)     627712      ['tf_conv_15[0][0]']             \n",
            "                                                                                                  \n",
            " tf_conv_25 (TFConv)            (1, 20, 20, 512)     1181696     ['tfc3_2[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_3 (TFC3)                  (1, 20, 20, 512)     1185792     ['tf_conv_25[0][0]']             \n",
            "                                                                                                  \n",
            " tfsppf (TFSPPF)                (1, 20, 20, 512)     658432      ['tfc3_3[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_conv_33 (TFConv)            (1, 20, 20, 256)     132096      ['tfsppf[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_upsample (TFUpsample)       (1, 40, 40, 256)     0           ['tf_conv_33[0][0]']             \n",
            "                                                                                                  \n",
            " tf_concat (TFConcat)           (1, 40, 40, 512)     0           ['tf_upsample[0][0]',            \n",
            "                                                                  'tfc3_2[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_4 (TFC3)                  (1, 40, 40, 256)     363520      ['tf_concat[0][0]']              \n",
            "                                                                                                  \n",
            " tf_conv_39 (TFConv)            (1, 40, 40, 128)     33280       ['tfc3_4[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_upsample_1 (TFUpsample)     (1, 80, 80, 128)     0           ['tf_conv_39[0][0]']             \n",
            "                                                                                                  \n",
            " tf_concat_1 (TFConcat)         (1, 80, 80, 256)     0           ['tf_upsample_1[0][0]',          \n",
            "                                                                  'tfc3_1[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_5 (TFC3)                  (1, 80, 80, 128)     91648       ['tf_concat_1[0][0]']            \n",
            "                                                                                                  \n",
            " tf_conv_45 (TFConv)            (1, 40, 40, 128)     147968      ['tfc3_5[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_concat_2 (TFConcat)         (1, 40, 40, 256)     0           ['tf_conv_45[0][0]',             \n",
            "                                                                  'tf_conv_39[0][0]']             \n",
            "                                                                                                  \n",
            " tfc3_6 (TFC3)                  (1, 40, 40, 256)     297984      ['tf_concat_2[0][0]']            \n",
            "                                                                                                  \n",
            " tf_conv_51 (TFConv)            (1, 20, 20, 256)     590848      ['tfc3_6[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_concat_3 (TFConcat)         (1, 20, 20, 512)     0           ['tf_conv_51[0][0]',             \n",
            "                                                                  'tf_conv_33[0][0]']             \n",
            "                                                                                                  \n",
            " tfc3_7 (TFC3)                  (1, 20, 20, 512)     1185792     ['tf_concat_3[0][0]']            \n",
            "                                                                                                  \n",
            " tf_detect (TFDetect)           ((1, 25200, 7),      18879       ['tfc3_5[0][0]',                 \n",
            "                                 [(1, 3, 6400, 7),                'tfc3_6[0][0]',                 \n",
            "                                 (1, 3, 1600, 7),                 'tfc3_7[0][0]']                 \n",
            "                                 (1, 3, 400, 7)])                                                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,044,031\n",
            "Trainable params: 7,025,023\n",
            "Non-trainable params: 19,008\n",
            "__________________________________________________________________________________________________\n",
            "PyTorch, TensorFlow and Keras models successfully verified.\n",
            "Use export.py for TF model export.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python export.py --weights /content/yolov5/runs/train/exp/weights/best.pt --include tflite"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmoCi12Uqovl",
        "outputId": "c36b75a7-5e5b-423e-969e-294c5a9ce42b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mexport: \u001b[0mdata=data/coco128.yaml, weights=['/content/yolov5/runs/train/exp/weights/best.pt'], imgsz=[640, 640], batch_size=1, device=cpu, half=False, inplace=False, train=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=12, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['tflite']\n",
            "YOLOv5 🚀 v6.0-255-gca0a007 torch 1.10.0+cu111 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 213 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from /content/yolov5/runs/train/exp/weights/best.pt with output shape (1, 25200, 7) (14.4 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.7.0...\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "2022-02-15 09:17:06.550786: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  1    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512], [640, 640]]\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(1, 640, 640, 3)]   0           []                               \n",
            "                                                                                                  \n",
            " tf_conv (TFConv)               (1, 320, 320, 32)    3488        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " tf_conv_1 (TFConv)             (1, 160, 160, 64)    18496       ['tf_conv[0][0]']                \n",
            "                                                                                                  \n",
            " tfc3 (TFC3)                    (1, 160, 160, 64)    18624       ['tf_conv_1[0][0]']              \n",
            "                                                                                                  \n",
            " tf_conv_7 (TFConv)             (1, 80, 80, 128)     73856       ['tfc3[0][0]']                   \n",
            "                                                                                                  \n",
            " tfc3_1 (TFC3)                  (1, 80, 80, 128)     115200      ['tf_conv_7[0][0]']              \n",
            "                                                                                                  \n",
            " tf_conv_15 (TFConv)            (1, 40, 40, 256)     295168      ['tfc3_1[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_2 (TFC3)                  (1, 40, 40, 256)     623872      ['tf_conv_15[0][0]']             \n",
            "                                                                                                  \n",
            " tf_conv_25 (TFConv)            (1, 20, 20, 512)     1180160     ['tfc3_2[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_3 (TFC3)                  (1, 20, 20, 512)     1181184     ['tf_conv_25[0][0]']             \n",
            "                                                                                                  \n",
            " tfsppf (TFSPPF)                (1, 20, 20, 512)     656128      ['tfc3_3[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_conv_33 (TFConv)            (1, 20, 20, 256)     131328      ['tfsppf[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_upsample (TFUpsample)       (1, 40, 40, 256)     0           ['tf_conv_33[0][0]']             \n",
            "                                                                                                  \n",
            " tf_concat (TFConcat)           (1, 40, 40, 512)     0           ['tf_upsample[0][0]',            \n",
            "                                                                  'tfc3_2[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_4 (TFC3)                  (1, 40, 40, 256)     361216      ['tf_concat[0][0]']              \n",
            "                                                                                                  \n",
            " tf_conv_39 (TFConv)            (1, 40, 40, 128)     32896       ['tfc3_4[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_upsample_1 (TFUpsample)     (1, 80, 80, 128)     0           ['tf_conv_39[0][0]']             \n",
            "                                                                                                  \n",
            " tf_concat_1 (TFConcat)         (1, 80, 80, 256)     0           ['tf_upsample_1[0][0]',          \n",
            "                                                                  'tfc3_1[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_5 (TFC3)                  (1, 80, 80, 128)     90496       ['tf_concat_1[0][0]']            \n",
            "                                                                                                  \n",
            " tf_conv_45 (TFConv)            (1, 40, 40, 128)     147584      ['tfc3_5[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_concat_2 (TFConcat)         (1, 40, 40, 256)     0           ['tf_conv_45[0][0]',             \n",
            "                                                                  'tf_conv_39[0][0]']             \n",
            "                                                                                                  \n",
            " tfc3_6 (TFC3)                  (1, 40, 40, 256)     295680      ['tf_concat_2[0][0]']            \n",
            "                                                                                                  \n",
            " tf_conv_51 (TFConv)            (1, 20, 20, 256)     590080      ['tfc3_6[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_concat_3 (TFConcat)         (1, 20, 20, 512)     0           ['tf_conv_51[0][0]',             \n",
            "                                                                  'tf_conv_33[0][0]']             \n",
            "                                                                                                  \n",
            " tfc3_7 (TFC3)                  (1, 20, 20, 512)     1181184     ['tf_concat_3[0][0]']            \n",
            "                                                                                                  \n",
            " tf_detect (TFDetect)           ((1, 25200, 7),      18879       ['tfc3_5[0][0]',                 \n",
            "                                 [(1, 3, 6400, 7),                'tfc3_6[0][0]',                 \n",
            "                                 (1, 3, 1600, 7),                 'tfc3_7[0][0]']                 \n",
            "                                 (1, 3, 400, 7)])                                                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,015,519\n",
            "Trainable params: 0\n",
            "Non-trainable params: 7,015,519\n",
            "__________________________________________________________________________________________________\n",
            "Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "2022-02-15 09:17:15.961000: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "Found untraced functions such as tf_conv_2_layer_call_fn, tf_conv_2_layer_call_and_return_conditional_losses, tf_conv_3_layer_call_fn, tf_conv_3_layer_call_and_return_conditional_losses, tf_conv_4_layer_call_fn while saving (showing 5 of 520). These functions will not be directly callable after loading.\n",
            "Assets written to: /content/yolov5/runs/train/exp/weights/best_saved_model/assets\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success, saved as /content/yolov5/runs/train/exp/weights/best_saved_model (238.6 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.7.0...\n",
            "Found untraced functions such as tf_conv_2_layer_call_fn, tf_conv_2_layer_call_and_return_conditional_losses, tf_conv_3_layer_call_fn, tf_conv_3_layer_call_and_return_conditional_losses, tf_conv_4_layer_call_fn while saving (showing 5 of 520). These functions will not be directly callable after loading.\n",
            "Assets written to: /tmp/tmpzvdoqiwh/assets\n",
            "2022-02-15 09:18:59.439775: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:363] Ignored output_format.\n",
            "2022-02-15 09:18:59.439840: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:366] Ignored drop_control_dependency.\n",
            "Estimated count of arithmetic ops: 17.346 G  ops, equivalently 8.673 G  MACs\n",
            "Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success, saved as /content/yolov5/runs/train/exp/weights/best-fp16.tflite (14.2 MB)\n",
            "\n",
            "Export complete (119.00s)\n",
            "Results saved to \u001b[1m/content/yolov5/runs/train/exp/weights\u001b[0m\n",
            "Detect:          python detect.py --weights /content/yolov5/runs/train/exp/weights/best-fp16.tflite\n",
            "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', '/content/yolov5/runs/train/exp/weights/best-fp16.tflite')\n",
            "Validate:        python val.py --weights /content/yolov5/runs/train/exp/weights/best-fp16.tflite\n",
            "Visualize:       https://netron.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('/content/yolov5/runs/train/exp/weights/best-fp16.tflite')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "qreJoY_rrtMl",
        "outputId": "95b41fb9-eaf6-4459-b941-0eda34c025b0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_dcd92d43-04d7-478c-be6c-e47a99b685fa\", \"best-fp16.tflite\", 14165856)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "from onnx_tf.backend import prepare\n",
        "\n",
        "base_model = onnx.load('/content/yolov5/runs/train/exp/weights/best.onnx')\n",
        "to_tf = prepare(base_model)\n",
        "to_tf.export_graph(\"/content/yolov5/runs/train/exp/weights/best.pb\")"
      ],
      "metadata": {
        "id": "X6ogdDeFYg73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "60f5aa86-6caa-4f3c-d280-c643534e34e6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m       \u001b[0mstr_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m       \u001b[0mstr_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/compat.py\u001b[0m in \u001b[0;36mas_bytes\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m     86\u001b[0m     raise TypeError('Expected binary or unicode string, got %r' %\n\u001b[0;32m---> 87\u001b[0;31m                     (bytes_or_text,))\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Expected binary or unicode string, got <bound method Kernel.raw_input of <google.colab._kernel.Kernel object at 0x7f6acdea32d0>>",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-6b57ea425a13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/yolov5/runs/train/exp/weights/best.onnx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/onnx_tf/backend_rep.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0minput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0minput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0moutput_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    270\u001b[0m   \"\"\"\n\u001b[1;32m    271\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 272\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    288\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[1;32m    289\u001b[0m           \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m           allow_broadcast=allow_broadcast))\n\u001b[0m\u001b[1;32m    291\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m   \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtensor_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdtype_value\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    547\u001b[0m       \u001b[0mstr_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m       raise TypeError(f\"Failed to convert elements of {values} to Tensor. \"\n\u001b[0m\u001b[1;32m    550\u001b[0m                       \u001b[0;34m\"Consider casting elements to a supported type. See \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                       \u001b[0;34m\"https://www.tensorflow.org/api_docs/python/tf/dtypes \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Failed to convert elements of <bound method Kernel.raw_input of <google.colab._kernel.Kernel object at 0x7f6acdea32d0>> to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pb to tflite\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "graph_def_file = \"/content/yolov5/runs/train/exp/weights/best.pb/saved_model.pb\"\n",
        "input_arrays = [\"images\"]\n",
        "output_arrays = [\"output\"]\n",
        "tflite_file = \"/content/yolov5/runs/train/exp/weights/best.tflite\"\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_frozen_graph(graph_def_file, input_arrays, output_arrays)\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "open(tflite_file, \"wb\").write(tflite_model)"
      ],
      "metadata": {
        "id": "CLDLgoClZGrh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "a128f44f-4770-469f-b4b5-fc3384080eca"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ignore 'tcmalloc: large alloc' warnings.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnicodeDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDecodeError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mfrom_frozen_graph\u001b[0;34m(cls, graph_def_file, input_arrays, output_arrays, input_shapes)\u001b[0m\n\u001b[1;32m   2453\u001b[0m           \u001b[0mgraph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_graph_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2454\u001b[0;31m           \u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2455\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_text_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDecodeError\u001b[0m: Error parsing message",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-2de4695968da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtflite_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/yolov5/runs/train/exp/weights/best.tflite\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_frozen_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_def_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mfrom_frozen_graph\u001b[0;34m(cls, graph_def_file, input_arrays, output_arrays, input_shapes)\u001b[0m\n\u001b[1;32m   2461\u001b[0m                 \u001b[0mfile_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2462\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2463\u001b[0;31m                 \u001b[0mfile_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2464\u001b[0m             \u001b[0mgraph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_graph_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2465\u001b[0m             \u001b[0m_text_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mensure_text\u001b[0;34m(s, encoding, errors)\u001b[0m\n\u001b[1;32m    933\u001b[0m     \"\"\"\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xcb in position 3: invalid continuation byte"
          ]
        }
      ]
    }
  ]
}