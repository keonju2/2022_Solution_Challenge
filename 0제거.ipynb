{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0제거.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMEwgtp8NKTYhdwBUWKiFb/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keonju2/sol_ch/blob/main/0%EC%A0%9C%EA%B1%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZ-2-yToPXO1",
        "outputId": "2dc2f158-bdc3-4ac1-d508-22d967ff0f6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#clone YOLOv5 and \n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt # install dependencies\n",
        "!pip install -q roboflow\n",
        "\n",
        "import torch\n",
        "from IPython.display import Image  # for displaying images\n",
        "import os \n",
        "import random\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xml.etree.ElementTree as ET\n",
        "from xml.dom import minidom\n",
        "from tqdm import tqdm\n",
        "from PIL import Image, ImageDraw\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiydCHPTPZBn",
        "outputId": "f0606aba-b719-4ecc-eac7-67d876b7dc3d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 11142, done.\u001b[K\n",
            "remote: Total 11142 (delta 0), reused 0 (delta 0), pack-reused 11142\u001b[K\n",
            "Receiving objects: 100% (11142/11142), 11.14 MiB | 32.40 MiB/s, done.\n",
            "Resolving deltas: 100% (7699/7699), done.\n",
            "/content/yolov5\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.21.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (7.1.2)\n",
            "Collecting PyYAML>=5.3.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (0.11.1+cu111)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (4.62.3)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (2.8.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (1.3.5)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 21)) (0.11.2)\n",
            "Collecting thop\n",
            "  Downloading thop-0.0.31.post2005241907-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.0.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2021.10.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r requirements.txt (line 11)) (3.10.0.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.3.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.43.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.37.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.4.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 20)) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.11.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.2.0)\n",
            "Installing collected packages: thop, PyYAML\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-6.0 thop-0.0.31.post2005241907\n",
            "\u001b[K     |████████████████████████████████| 67 kB 3.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 178 kB 30.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 138 kB 40.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 47.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 145 kB 59.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25h  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Setup complete. Using torch 1.10.0+cu111 (Tesla P100-PCIE-16GB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "import os\n",
        "\n",
        "def unzip(source_file, dest_path):\n",
        "    with ZipFile(source_file, 'r') as zf:\n",
        "        zipInfo = zf.infolist()\n",
        "        for member in zipInfo:\n",
        "            try:\n",
        "                member.filename = member.filename.encode('cp437').decode('euc-kr', 'ignore')\n",
        "                zf.extract(member, dest_path)\n",
        "            except:\n",
        "                raise Exception('what?!')"
      ],
      "metadata": {
        "id": "mwMxiiqRPcUR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q wandb\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "k82A_5lWPe9F",
        "outputId": "f51aae77-a91b-4800-c00a-abc569b87613"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 48.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 48.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_names = '/content/gdrive/MyDrive/custom_dataset.zip'\n",
        "unzip(file_names,'/content/yolov5/custom_dataset')"
      ],
      "metadata": {
        "id": "1M3LylFoPf8k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "file_source = '/content/yolov5/custom_dataset/custom_dataset/train/labels'\n",
        "file_dest = '/content/yolov5/custom_dataset/custom_dataset/val/labels'\n",
        "file_dest2 = '/content/yolov5/data/detect/labels'\n",
        "\n",
        "get_file = os.listdir(file_source)\n",
        "for i in get_file:\n",
        "  if 'Q_0' in i:\n",
        "    move_file = file_source + '/' + i\n",
        "    shutil.move(move_file, file_dest2)"
      ],
      "metadata": {
        "id": "ZOb-FlqOPhKR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_source = '/content/yolov5/custom_dataset/custom_dataset/test/labels'\n",
        "file_dest = '/content/yolov5/custom_dataset/custom_dataset/val/labels'\n",
        "file_dest2 = '/content/yolov5/data/detect/labels'\n",
        "\n",
        "get_file = os.listdir(file_source)\n",
        "for i in get_file:\n",
        "  if 'Q_0' in i or 'Q_1' in i :\n",
        "    move_file = file_source + '/' + i\n",
        "    shutil.move(move_file, file_dest2)\n",
        "  if len(i) == 6:\n",
        "    move_file = file_source + '/' + i\n",
        "    shutil.move(move_file, file_dest)"
      ],
      "metadata": {
        "id": "pvuvYSveWEK0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = '/content/gdrive/MyDrive/sc_data_zip/Training/image'\n",
        "train_list = os.listdir(file_name)\n",
        "print(train_list)\n",
        "for i in train_list:\n",
        "  file_names = file_name+'/'+i\n",
        "  if '실제도로환경' in i:\n",
        "      unzip(file_names,'/content/yolov5/custom_dataset/custom_dataset/train/images')\n",
        "\n",
        "  elif 'keypoint' in file_names:\n",
        "      unzip(file_names,'/content/yolov5/data/detect/images')\n",
        "  else:\n",
        "      unzip(file_names,'/content/yolov5/custom_dataset/custom_dataset/train/images')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZolQr-AP8nH",
        "outputId": "322ee602-f9a2-43b0-9e22-905aa29e2d9b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[원천]bbox(실제도로환경).zip', '[원천]bbox(통제환경).zip', '[원천]keypoint(준통제환경).zip']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = '/content/gdrive/MyDrive/sc_data_zip/Validation/image'\n",
        "train_list = os.listdir(file_name)\n",
        "print(train_list)\n",
        "\n",
        "for i in train_list:\n",
        "  file_names = file_name+'/'+i\n",
        "  if '[원천]bbox(실제도로환경).zip' in i:\n",
        "      unzip(file_names,'/content/yolov5/custom_dataset/custom_dataset/test/images')\n",
        "  elif 'keypoint' in file_names:\n",
        "      unzip(file_names,'/content/yolov5/data/detect/images')\n",
        "  else:\n",
        "      unzip(file_names,'/content/yolov5/custom_dataset/custom_dataset/val/images')\n"
      ],
      "metadata": {
        "id": "60rtknQ9RiD8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0a5ae88-78ba-4a16-e8c4-7881b6621aac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[원천]bbox(실제도로환경).zip', '[원천]bbox(통제환경).zip', '[원천]keypoint(준통제환경).zip']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "make_yaml = {\n",
        "             \"train\" : \"/content/yolov5/custom_dataset/custom_dataset/train\",\n",
        "            \"test\": \"/content/yolov5/custom_dataset/custom_dataset/test\",\n",
        "            \"val\": \"/content/yolov5/custom_dataset/custom_dataset/val\",\n",
        "\n",
        "             \"nc\" : 4,\n",
        "             \"names\": [\"left_open_eye\",\"left_closed_eye\", \"right_open_eye\",\"right_closed_eye\"]\n",
        "}\n",
        "with open('/content/yolov5/data/custom_dataset.yaml', 'w') as outfile:\n",
        "    yaml.dump(make_yaml, outfile, default_flow_style=False)"
      ],
      "metadata": {
        "id": "_68rC70FRllS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 640 --cfg yolov5s.yaml --hyp /content/yolov5/data/hyps/hyp.scratch-high.yaml --batch 32 --epochs 3 --data /content/yolov5/data/custom_dataset.yaml --weights yolov5s.pt --workers 24"
      ],
      "metadata": {
        "id": "vQIDK9j8Rmn4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a1ee448-4616-4b9a-bb39-0188f65c95c2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkeonju2\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=yolov5s.yaml, data=/content/yolov5/data/custom_dataset.yaml, hyp=/content/yolov5/data/hyps/hyp.scratch-high.yaml, epochs=3, batch_size=32, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=24, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v6.1-11-g63ddb6f torch 1.10.0+cu111 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.1, copy_paste=0.1\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlogical-shape-7\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/keonju2/YOLOv5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/keonju2/YOLOv5/runs/tm5a68d5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/yolov5/wandb/run-20220228_000144-tm5a68d5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 114MB/s] \n",
            "\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model Summary: 270 layers, 7030417 parameters, 7030417 gradients, 15.9 GFLOPs\n",
            "\n",
            "Transferred 342/349 items from yolov5s.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/yolov5/custom_dataset/custom_dataset/train/labels/001_G1' images and labels...286116 found, 840 missing, 0 empty, 3 corrupt: 100% 286958/286958 [02:48<00:00, 1705.59it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /content/yolov5/custom_dataset/custom_dataset/train/images/2.승용/R_540_40_M/R_540_40_M_15_M0_G1_C0_11.jpg: ignoring corrupt image/label: negative label values [   -0.92917]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /content/yolov5/custom_dataset/custom_dataset/train/images/3.택시/R_314_60_M/R_314_60_M_09_M0_G1_C0_09.jpg: ignoring corrupt image/label: cannot identify image file '/content/yolov5/custom_dataset/custom_dataset/train/images/3.택시/R_314_60_M/R_314_60_M_09_M0_G1_C0_09.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /content/yolov5/custom_dataset/custom_dataset/train/images/3.택시/R_314_60_M/R_314_60_M_12_M0_G1_C0_09.jpg: ignoring corrupt image/label: cannot identify image file '/content/yolov5/custom_dataset/custom_dataset/train/images/3.택시/R_314_60_M/R_314_60_M_12_M0_G1_C0_09.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: /content/yolov5/custom_dataset/custom_dataset/train/images/3.택시/R_314_60_M/R_314_60_M_15_M0_G1_C0_06.jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov5/custom_dataset/custom_dataset/train/labels/001_G1.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5/custom_dataset/custom_dataset/val/labels/045_G1' images and labels...12073 found, 490 missing, 0 empty, 0 corrupt: 100% 12563/12563 [00:11<00:00, 1060.24it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov5/custom_dataset/custom_dataset/val/labels/045_G1.cache\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.47 anchors/target, 0.975 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING: Extremely small objects found: 14353 of 572230 labels are < 3 pixels in size\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 557880 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9188: 100% 1000/1000 [01:49<00:00,  9.09it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 0.9749 best possible recall, 8.77 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=640, metric_all=0.696/0.896-mean/best, past_thr=0.714-mean: 21,10, 27,12, 24,16, 31,14, 28,19, 35,18, 36,21, 40,20, 42,24\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ⚠️ (original anchors better than new anchors, proceeding with original anchors)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 4 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       0/2     6.98G    0.1194    0.0144   0.02462       156       640:   2% 196/8968 [03:27<2:09:54,  1.13it/s]Corrupt JPEG data: premature end of data segment\n",
            "       0/2     6.98G   0.06743   0.01188   0.02183       114       640:  23% 2070/8968 [34:45<1:38:02,  1.17it/s]Corrupt JPEG data: premature end of data segment\n",
            "       0/2     6.98G   0.05558  0.009821   0.02084       155       640:  45% 4061/8968 [1:08:08<1:19:00,  1.04it/s]Corrupt JPEG data: premature end of data segment\n",
            "       0/2     6.98G     0.053  0.009307   0.01978       126       640:  55% 4914/8968 [1:22:32<59:37,  1.13it/s]  Corrupt JPEG data: premature end of data segment\n",
            "       0/2     6.98G   0.04922  0.008533   0.01676       163       640:  76% 6772/8968 [1:53:49<30:36,  1.20it/s]Corrupt JPEG data: premature end of data segment\n",
            "       0/2     6.98G   0.04621  0.007964   0.01416        42       640: 100% 8968/8968 [2:30:18<00:00,  1.01s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 197/197 [01:40<00:00,  1.96it/s]\n",
            "                 all      12563      24146      0.867      0.841      0.834      0.427\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       1/2     6.98G   0.03431  0.006002  0.004796       102       640:   2% 212/8968 [03:19<2:05:04,  1.17it/s]Corrupt JPEG data: premature end of data segment\n",
            "       1/2     6.98G   0.03391  0.005913  0.004728       139       640:  10% 927/8968 [15:10<2:04:29,  1.08it/s]Corrupt JPEG data: premature end of data segment\n",
            "       1/2     6.98G   0.03393  0.005904  0.004748       165       640:  13% 1152/8968 [18:52<1:49:32,  1.19it/s]Corrupt JPEG data: premature end of data segment\n",
            "       1/2     6.98G   0.03394  0.005912  0.004748       157       640:  27% 2389/8968 [39:22<2:00:15,  1.10s/it]Corrupt JPEG data: premature end of data segment\n",
            "       1/2     6.98G   0.03372  0.005875  0.004647       118       640:  50% 4448/8968 [1:13:47<1:10:22,  1.07it/s]Corrupt JPEG data: premature end of data segment\n",
            "       1/2     6.98G   0.03421  0.005878  0.004639       130       640:  57% 5090/8968 [1:24:35<1:11:26,  1.11s/it]Corrupt JPEG data: premature end of data segment\n",
            "       1/2     6.98G   0.03427  0.005876   0.00464       116       640:  58% 5212/8968 [1:26:37<58:05,  1.08it/s]  Corrupt JPEG data: premature end of data segment\n",
            "       1/2     6.98G   0.03452  0.005871  0.004598       116       640:  71% 6395/8968 [1:46:32<47:02,  1.10s/it]Corrupt JPEG data: premature end of data segment\n",
            "       1/2     6.98G   0.03452  0.005858  0.004541        92       640:  93% 8309/8968 [2:18:40<08:55,  1.23it/s]Corrupt JPEG data: premature end of data segment\n",
            "       1/2     6.98G   0.03452  0.005857  0.004543       125       640:  93% 8326/8968 [2:18:58<12:03,  1.13s/it]Corrupt JPEG data: premature end of data segment\n",
            "       1/2     6.98G   0.03447  0.005852  0.004533       129       640:  97% 8743/8968 [2:25:58<04:22,  1.16s/it]Corrupt JPEG data: premature end of data segment\n",
            "       1/2     6.98G   0.03444   0.00585  0.004535        43       640: 100% 8968/8968 [2:29:45<00:00,  1.00s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 197/197 [01:40<00:00,  1.95it/s]\n",
            "                 all      12563      24146      0.894      0.861      0.853      0.453\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       2/2     6.98G   0.03227  0.005625   0.00511       146       640:   0% 34/8968 [00:30<2:40:47,  1.08s/it]Corrupt JPEG data: premature end of data segment\n",
            "       2/2     6.98G   0.03084  0.005532  0.003673       117       640:  25% 2247/8968 [37:43<1:34:30,  1.19it/s]Corrupt JPEG data: premature end of data segment\n",
            "       2/2     6.98G   0.03063   0.00552  0.003677       128       640:  49% 4359/8968 [1:13:15<1:01:49,  1.24it/s]Corrupt JPEG data: premature end of data segment\n",
            "       2/2     6.98G   0.03056   0.00552  0.003688       137       640:  56% 5053/8968 [1:24:56<1:10:31,  1.08s/it]Corrupt JPEG data: premature end of data segment\n",
            "       2/2     6.98G   0.03055  0.005521  0.003691       131       640:  58% 5175/8968 [1:27:00<53:11,  1.19it/s]Corrupt JPEG data: premature end of data segment\n",
            "       2/2     6.98G   0.03045  0.005522  0.003718       130       640:  73% 6526/8968 [1:49:46<38:42,  1.05it/s]Corrupt JPEG data: premature end of data segment\n",
            "       2/2     6.98G   0.03043  0.005533  0.003772        56       640: 100% 8968/8968 [2:30:53<00:00,  1.01s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 197/197 [01:41<00:00,  1.93it/s]\n",
            "                 all      12563      24146      0.897      0.865      0.855      0.461\n",
            "\n",
            "3 epochs completed in 7.602 hours.\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 14.4MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 14.4MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model Summary: 213 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 197/197 [01:56<00:00,  1.70it/s]\n",
            "                 all      12563      24146      0.897      0.865      0.855      0.461\n",
            "       left_open_eye      12563       8627      0.928      0.977      0.952      0.563\n",
            "     left_closed_eye      12563       3446      0.892      0.846      0.848      0.414\n",
            "      right_open_eye      12563       8214      0.906      0.966      0.949      0.541\n",
            "    right_closed_eye      12563       3859      0.864      0.672      0.672      0.324\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 568... (success).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP_0.5 ▁▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   metrics/mAP_0.5:0.95 ▁▆██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/precision ▁▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         metrics/recall ▁▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/box_loss █▃▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/cls_loss █▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/obj_loss █▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/box_loss █▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/cls_loss █▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/obj_loss █▃▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr0 ▁█▅\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr1 ▁█▅\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr2 █▅▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             best/epoch 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           best/mAP_0.5 0.85505\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      best/mAP_0.5:0.95 0.46067\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         best/precision 0.89746\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            best/recall 0.86511\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP_0.5 0.8551\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   metrics/mAP_0.5:0.95 0.46079\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/precision 0.89735\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         metrics/recall 0.86524\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/box_loss 0.03043\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/cls_loss 0.00377\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/obj_loss 0.00553\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/box_loss 0.02865\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/cls_loss 0.00204\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/obj_loss 0.00633\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr0 0.004\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr1 0.004\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr2 0.004\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 113 media file(s), 1 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mlogical-shape-7\u001b[0m: \u001b[34mhttps://wandb.ai/keonju2/YOLOv5/runs/tm5a68d5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: ./wandb/run-20220228_000144-tm5a68d5/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = '/content/gdrive/MyDrive/result/fourth'\n",
        "save_file_path = '/content/yolov5/runs/train'\n",
        "\n",
        "shutil.move(save_file_path, save_path)"
      ],
      "metadata": {
        "id": "ed6OcgYpR7WX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "60124e5a-b456-44d5-d299-01d282a7abdb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/MyDrive/result/fourth'"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --source /content/yolov5/data/detect/images/Q_001_30_M_01_M0_G0_C0 --weights /content/gdrive/MyDrive/result/fourth/exp/weights/best.pt --conf 0.25 --name exp"
      ],
      "metadata": {
        "id": "4ZlUjqNWR1K1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c73e8202-a3df-4f3c-ae54-fb71230649cd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/gdrive/MyDrive/result/fourth/exp/weights/best.pt'], source=/content/yolov5/data/detect/images/Q_001_30_M_01_M0_G0_C0, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v6.1-11-g63ddb6f torch 1.10.0+cu111 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 213 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n",
            "image 1/25 /content/yolov5/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_01.jpg: 640x384 1 left_open_eye, 1 left_closed_eye, 1 right_open_eye, 1 right_closed_eye, Done. (0.016s)\n",
            "image 2/25 /content/yolov5/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_02.jpg: 640x384 1 left_open_eye, 1 left_closed_eye, 1 right_closed_eye, Done. (0.011s)\n",
            "image 3/25 /content/yolov5/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_03.jpg: 640x384 1 left_open_eye, 1 left_closed_eye, 1 right_closed_eye, Done. (0.011s)\n",
            "image 4/25 /content/yolov5/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_04.jpg: 640x384 1 left_closed_eye, 1 right_closed_eye, Done. (0.011s)\n",
            "image 5/25 /content/yolov5/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_05.jpg: 640x384 1 left_closed_eye, 1 right_closed_eye, Done. (0.011s)\n",
            "image 6/25 /content/yolov5/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_06.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.011s)\n",
            "image 7/25 /content/yolov5/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_07.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.015s)\n",
            "image 8/25 /content/yolov5/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_08.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.015s)\n",
            "image 9/25 /content/yolov5/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_09.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.011s)\n",
            "image 10/25 /content/yolov5/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_10.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.012s)\n",
            "image 11/25 /content/yolov5/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_11.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.012s)\n",
            "image 12/25 /content/yolov5/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_12.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.012s)\n",
            "image 13/25 /content/yolov5/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_13.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.012s)\n",
            "image 14/25 /content/yolov5/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_14.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.012s)\n",
            "image 15/25 /content/yolov5/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_15.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.011s)\n",
            "image 16/25 /content/yolov5/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_16.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.012s)\n",
            "image 17/25 /content/yolov5/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_17.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.011s)\n",
            "image 18/25 /content/yolov5/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_18.jpg: 640x384 1 left_closed_eye, 1 right_open_eye, Done. (0.011s)\n",
            "image 19/25 /content/yolov5/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_19.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.011s)\n",
            "image 20/25 /content/yolov5/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_20.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.011s)\n",
            "image 21/25 /content/yolov5/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_21.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.011s)\n",
            "image 22/25 /content/yolov5/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_22.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.011s)\n",
            "image 23/25 /content/yolov5/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_23.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.013s)\n",
            "image 24/25 /content/yolov5/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_24.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.010s)\n",
            "image 25/25 /content/yolov5/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_25.jpg: 640x384 1 left_closed_eye, 1 right_closed_eye, Done. (0.010s)\n",
            "Speed: 0.4ms pre-process, 11.7ms inference, 1.5ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python models/tf.py --weights /content/gdrive/MyDrive/result/fourth/exp/weights/best.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szoE0v3cqeRU",
        "outputId": "1aa8d48f-c5a4-4c07-ae28-38f389b1bdbc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtf: \u001b[0mweights=/content/gdrive/MyDrive/result/fourth/exp/weights/best.pt, imgsz=[640, 640], batch_size=1, dynamic=False\n",
            "Model Summary: 270 layers, 7030417 parameters, 0 gradients, 15.9 GFLOPs\n",
            "2022-02-28 07:46:38.928694: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  1    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512], [640, 640]]\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(1, 640, 640, 3)]   0           []                               \n",
            "                                                                                                  \n",
            " tf_conv (TFConv)               (1, 320, 320, 32)    3584        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " tf_conv_1 (TFConv)             (1, 160, 160, 64)    18688       ['tf_conv[0][0]']                \n",
            "                                                                                                  \n",
            " tfc3 (TFC3)                    (1, 160, 160, 64)    19200       ['tf_conv_1[0][0]']              \n",
            "                                                                                                  \n",
            " tf_conv_7 (TFConv)             (1, 80, 80, 128)     74240       ['tfc3[0][0]']                   \n",
            "                                                                                                  \n",
            " tfc3_1 (TFC3)                  (1, 80, 80, 128)     116736      ['tf_conv_7[0][0]']              \n",
            "                                                                                                  \n",
            " tf_conv_15 (TFConv)            (1, 40, 40, 256)     295936      ['tfc3_1[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_2 (TFC3)                  (1, 40, 40, 256)     627712      ['tf_conv_15[0][0]']             \n",
            "                                                                                                  \n",
            " tf_conv_25 (TFConv)            (1, 20, 20, 512)     1181696     ['tfc3_2[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_3 (TFC3)                  (1, 20, 20, 512)     1185792     ['tf_conv_25[0][0]']             \n",
            "                                                                                                  \n",
            " tfsppf (TFSPPF)                (1, 20, 20, 512)     658432      ['tfc3_3[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_conv_33 (TFConv)            (1, 20, 20, 256)     132096      ['tfsppf[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_upsample (TFUpsample)       (1, 40, 40, 256)     0           ['tf_conv_33[0][0]']             \n",
            "                                                                                                  \n",
            " tf_concat (TFConcat)           (1, 40, 40, 512)     0           ['tf_upsample[0][0]',            \n",
            "                                                                  'tfc3_2[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_4 (TFC3)                  (1, 40, 40, 256)     363520      ['tf_concat[0][0]']              \n",
            "                                                                                                  \n",
            " tf_conv_39 (TFConv)            (1, 40, 40, 128)     33280       ['tfc3_4[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_upsample_1 (TFUpsample)     (1, 80, 80, 128)     0           ['tf_conv_39[0][0]']             \n",
            "                                                                                                  \n",
            " tf_concat_1 (TFConcat)         (1, 80, 80, 256)     0           ['tf_upsample_1[0][0]',          \n",
            "                                                                  'tfc3_1[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_5 (TFC3)                  (1, 80, 80, 128)     91648       ['tf_concat_1[0][0]']            \n",
            "                                                                                                  \n",
            " tf_conv_45 (TFConv)            (1, 40, 40, 128)     147968      ['tfc3_5[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_concat_2 (TFConcat)         (1, 40, 40, 256)     0           ['tf_conv_45[0][0]',             \n",
            "                                                                  'tf_conv_39[0][0]']             \n",
            "                                                                                                  \n",
            " tfc3_6 (TFC3)                  (1, 40, 40, 256)     297984      ['tf_concat_2[0][0]']            \n",
            "                                                                                                  \n",
            " tf_conv_51 (TFConv)            (1, 20, 20, 256)     590848      ['tfc3_6[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_concat_3 (TFConcat)         (1, 20, 20, 512)     0           ['tf_conv_51[0][0]',             \n",
            "                                                                  'tf_conv_33[0][0]']             \n",
            "                                                                                                  \n",
            " tfc3_7 (TFC3)                  (1, 20, 20, 512)     1185792     ['tf_concat_3[0][0]']            \n",
            "                                                                                                  \n",
            " tf_detect (TFDetect)           ((1, 25200, 9),      24273       ['tfc3_5[0][0]',                 \n",
            "                                 [(1, 3, 6400, 9),                'tfc3_6[0][0]',                 \n",
            "                                 (1, 3, 1600, 9),                 'tfc3_7[0][0]']                 \n",
            "                                 (1, 3, 400, 9)])                                                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,049,425\n",
            "Trainable params: 7,030,417\n",
            "Non-trainable params: 19,008\n",
            "__________________________________________________________________________________________________\n",
            "PyTorch, TensorFlow and Keras models successfully verified.\n",
            "Use export.py for TF model export.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = '/content/gdrive/MyDrive/result/fourth/detect'\n",
        "save_file_path = '/content/yolov5/runs/detect/exp'\n",
        "\n",
        "shutil.move(save_file_path, save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "a2WJCeo8XdMU",
        "outputId": "16982dba-ba79-4e06-ccba-289607d665a4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/MyDrive/result/fourth/detect'"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python export.py --weights /content/gdrive/MyDrive/result/fourth/exp/weights/best.pt --include tflite"
      ],
      "metadata": {
        "id": "48eKwFheR8pF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1f98371-230d-44ab-c2ee-459af5300974"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mexport: \u001b[0mdata=data/coco128.yaml, weights=['/content/gdrive/MyDrive/result/fourth/exp/weights/best.pt'], imgsz=[640, 640], batch_size=1, device=cpu, half=False, inplace=False, train=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=12, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['tflite']\n",
            "YOLOv5 🚀 v6.1-11-g63ddb6f torch 1.10.0+cu111 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 213 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from /content/gdrive/MyDrive/result/fourth/exp/weights/best.pt with output shape (1, 25200, 9) (14.4 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.8.0...\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "2022-02-28 07:53:00.946172: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  1    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512], [640, 640]]\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(1, 640, 640, 3)]   0           []                               \n",
            "                                                                                                  \n",
            " tf_conv (TFConv)               (1, 320, 320, 32)    3488        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " tf_conv_1 (TFConv)             (1, 160, 160, 64)    18496       ['tf_conv[0][0]']                \n",
            "                                                                                                  \n",
            " tfc3 (TFC3)                    (1, 160, 160, 64)    18624       ['tf_conv_1[0][0]']              \n",
            "                                                                                                  \n",
            " tf_conv_7 (TFConv)             (1, 80, 80, 128)     73856       ['tfc3[0][0]']                   \n",
            "                                                                                                  \n",
            " tfc3_1 (TFC3)                  (1, 80, 80, 128)     115200      ['tf_conv_7[0][0]']              \n",
            "                                                                                                  \n",
            " tf_conv_15 (TFConv)            (1, 40, 40, 256)     295168      ['tfc3_1[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_2 (TFC3)                  (1, 40, 40, 256)     623872      ['tf_conv_15[0][0]']             \n",
            "                                                                                                  \n",
            " tf_conv_25 (TFConv)            (1, 20, 20, 512)     1180160     ['tfc3_2[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_3 (TFC3)                  (1, 20, 20, 512)     1181184     ['tf_conv_25[0][0]']             \n",
            "                                                                                                  \n",
            " tfsppf (TFSPPF)                (1, 20, 20, 512)     656128      ['tfc3_3[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_conv_33 (TFConv)            (1, 20, 20, 256)     131328      ['tfsppf[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_upsample (TFUpsample)       (1, 40, 40, 256)     0           ['tf_conv_33[0][0]']             \n",
            "                                                                                                  \n",
            " tf_concat (TFConcat)           (1, 40, 40, 512)     0           ['tf_upsample[0][0]',            \n",
            "                                                                  'tfc3_2[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_4 (TFC3)                  (1, 40, 40, 256)     361216      ['tf_concat[0][0]']              \n",
            "                                                                                                  \n",
            " tf_conv_39 (TFConv)            (1, 40, 40, 128)     32896       ['tfc3_4[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_upsample_1 (TFUpsample)     (1, 80, 80, 128)     0           ['tf_conv_39[0][0]']             \n",
            "                                                                                                  \n",
            " tf_concat_1 (TFConcat)         (1, 80, 80, 256)     0           ['tf_upsample_1[0][0]',          \n",
            "                                                                  'tfc3_1[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_5 (TFC3)                  (1, 80, 80, 128)     90496       ['tf_concat_1[0][0]']            \n",
            "                                                                                                  \n",
            " tf_conv_45 (TFConv)            (1, 40, 40, 128)     147584      ['tfc3_5[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_concat_2 (TFConcat)         (1, 40, 40, 256)     0           ['tf_conv_45[0][0]',             \n",
            "                                                                  'tf_conv_39[0][0]']             \n",
            "                                                                                                  \n",
            " tfc3_6 (TFC3)                  (1, 40, 40, 256)     295680      ['tf_concat_2[0][0]']            \n",
            "                                                                                                  \n",
            " tf_conv_51 (TFConv)            (1, 20, 20, 256)     590080      ['tfc3_6[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_concat_3 (TFConcat)         (1, 20, 20, 512)     0           ['tf_conv_51[0][0]',             \n",
            "                                                                  'tf_conv_33[0][0]']             \n",
            "                                                                                                  \n",
            " tfc3_7 (TFC3)                  (1, 20, 20, 512)     1181184     ['tf_concat_3[0][0]']            \n",
            "                                                                                                  \n",
            " tf_detect (TFDetect)           ((1, 25200, 9),      24273       ['tfc3_5[0][0]',                 \n",
            "                                 [(1, 3, 6400, 9),                'tfc3_6[0][0]',                 \n",
            "                                 (1, 3, 1600, 9),                 'tfc3_7[0][0]']                 \n",
            "                                 (1, 3, 400, 9)])                                                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,020,913\n",
            "Trainable params: 0\n",
            "Non-trainable params: 7,020,913\n",
            "__________________________________________________________________________________________________\n",
            "2022-02-28 07:53:07.432191: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "Assets written to: /content/gdrive/MyDrive/result/fourth/exp/weights/best_saved_model/assets\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success, saved as /content/gdrive/MyDrive/result/fourth/exp/weights/best_saved_model (28.4 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.8.0...\n",
            "Found untraced functions such as tf_conv_2_layer_call_fn, tf_conv_2_layer_call_and_return_conditional_losses, tf_conv_3_layer_call_fn, tf_conv_3_layer_call_and_return_conditional_losses, tf_conv_4_layer_call_fn while saving (showing 5 of 208). These functions will not be directly callable after loading.\n",
            "Assets written to: /tmp/tmpx9rj2hh0/assets\n",
            "2022-02-28 07:54:11.306213: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
            "2022-02-28 07:54:11.306282: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
            "Estimated count of arithmetic ops: 17.366 G  ops, equivalently 8.683 G  MACs\n",
            "Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success, saved as /content/gdrive/MyDrive/result/fourth/exp/weights/best-fp16.tflite (14.2 MB)\n",
            "\n",
            "Export complete (76.33s)\n",
            "Results saved to \u001b[1m/content/gdrive/MyDrive/result/fourth/exp/weights\u001b[0m\n",
            "Detect:          python detect.py --weights /content/gdrive/MyDrive/result/fourth/exp/weights/best-fp16.tflite\n",
            "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', '/content/gdrive/MyDrive/result/fourth/exp/weights/best-fp16.tflite')\n",
            "Validate:        python val.py --weights /content/gdrive/MyDrive/result/fourth/exp/weights/best-fp16.tflite\n",
            "Visualize:       https://netron.app\n"
          ]
        }
      ]
    }
  ]
}