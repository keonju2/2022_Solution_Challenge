{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "meta.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNdjSi6DN6MjnlNewdoEB0h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keonju2/sol_ch/blob/main/meta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZ-2-yToPXO1",
        "outputId": "666fc9c7-27f9-4411-f9aa-c9e58e9a3e01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#clone YOLOv5 and \n",
        "!git clone https://github.com/hansheng0512/yolov5-tflite\n",
        " # clone repo\n",
        "%cd yolov5-tflite\n",
        "!pip install -r requirements.txt # install dependencies\n",
        "!pip install -q roboflow\n",
        "\n",
        "import torch\n",
        "from IPython.display import Image  # for displaying images\n",
        "import os \n",
        "import random\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xml.etree.ElementTree as ET\n",
        "from xml.dom import minidom\n",
        "from tqdm import tqdm\n",
        "from PIL import Image, ImageDraw\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiydCHPTPZBn",
        "outputId": "6b03ba99-659f-4189-b3ac-d6df211e59a0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5-tflite'...\n",
            "remote: Enumerating objects: 58, done.\u001b[K\n",
            "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 58 (delta 4), reused 58 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (58/58), done.\n",
            "/content/yolov5-tflite\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.21.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (7.1.2)\n",
            "Collecting PyYAML>=5.3.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (0.11.1+cu111)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (4.63.0)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 15)) (2.8.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 19)) (1.3.5)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (0.11.2)\n",
            "Collecting thop\n",
            "  Downloading thop-0.0.31.post2005241907-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r requirements.txt (line 10)) (3.10.0.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.3.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.44.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (2.23.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.37.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.17.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 19)) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 15)) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.2.0)\n",
            "Installing collected packages: thop, PyYAML\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-6.0 thop-0.0.31.post2005241907\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 12.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 935 kB/s \n",
            "\u001b[K     |████████████████████████████████| 138 kB 95.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 145 kB 70.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 178 kB 76.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.3 MB/s \n",
            "\u001b[?25h  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Setup complete. Using torch 1.10.0+cu111 (Tesla P100-PCIE-16GB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "import os\n",
        "\n",
        "def unzip(source_file, dest_path):\n",
        "    with ZipFile(source_file, 'r') as zf:\n",
        "        zipInfo = zf.infolist()\n",
        "        for member in zipInfo:\n",
        "            try:\n",
        "                member.filename = member.filename.encode('cp437').decode('euc-kr', 'ignore')\n",
        "                zf.extract(member, dest_path)\n",
        "            except:\n",
        "                raise Exception('what?!')"
      ],
      "metadata": {
        "id": "mwMxiiqRPcUR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -q wandb\n",
        "#import wandb\n",
        "#wandb.login()"
      ],
      "metadata": {
        "id": "k82A_5lWPe9F"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_names = '/content/gdrive/MyDrive/custom_dataset.zip'\n",
        "unzip(file_names,'/content/yolov5-tflite/custom_dataset')"
      ],
      "metadata": {
        "id": "1M3LylFoPf8k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "file_source = '/content/yolov5-tflite/custom_dataset/custom_dataset/train/labels'\n",
        "file_dest = '/content/yolov5-tflite/custom_dataset/custom_dataset/val/labels'\n",
        "file_dest2 = '/content/yolov5-tflite/data/detect/labels'\n",
        "\n",
        "get_file = os.listdir(file_source)\n",
        "for i in get_file:\n",
        "  if 'Q_0' in i:\n",
        "    move_file = file_source + '/' + i\n",
        "    shutil.move(move_file, file_dest2)"
      ],
      "metadata": {
        "id": "ZOb-FlqOPhKR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_source = '/content/yolov5-tflite/custom_dataset/custom_dataset/test/labels'\n",
        "file_dest = '/content/yolov5-tflite/custom_dataset/custom_dataset/val/labels'\n",
        "file_dest2 = '/content/yolov5-tflite/data/detect/labels'\n",
        "\n",
        "get_file = os.listdir(file_source)\n",
        "for i in get_file:\n",
        "  if 'Q_0' in i or 'Q_1' in i :\n",
        "    move_file = file_source + '/' + i\n",
        "    shutil.move(move_file, file_dest2)\n",
        "  if len(i) == 6:\n",
        "    move_file = file_source + '/' + i\n",
        "    shutil.move(move_file, file_dest)"
      ],
      "metadata": {
        "id": "pvuvYSveWEK0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = '/content/gdrive/MyDrive/sc_data_zip/Training/image'\n",
        "train_list = os.listdir(file_name)\n",
        "print(train_list)\n",
        "for i in train_list:\n",
        "  file_names = file_name+'/'+i\n",
        "  if '실제도로환경' in i:\n",
        "      unzip(file_names,'/content/yolov5-tflite/custom_dataset/custom_dataset/train/images')\n",
        "\n",
        "  elif 'keypoint' in file_names:\n",
        "      unzip(file_names,'/content/yolov5-tflite/data/detect/images')\n",
        "  else:\n",
        "      unzip(file_names,'/content/yolov5-tflite/custom_dataset/custom_dataset/train/images')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZolQr-AP8nH",
        "outputId": "e9486ade-213f-42be-ad50-fe8071a9da52"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[원천]bbox(실제도로환경).zip', '[원천]bbox(통제환경).zip', '[원천]keypoint(준통제환경).zip']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = '/content/gdrive/MyDrive/sc_data_zip/Validation/image'\n",
        "train_list = os.listdir(file_name)\n",
        "print(train_list)\n",
        "\n",
        "for i in train_list:\n",
        "  file_names = file_name+'/'+i\n",
        "  if '[원천]bbox(실제도로환경).zip' in i:\n",
        "      unzip(file_names,'/content/yolov5-tflite/custom_dataset/custom_dataset/test/images')\n",
        "  elif 'keypoint' in file_names:\n",
        "      unzip(file_names,'/content/yolov5-tflite/data/detect/images')\n",
        "  else:\n",
        "      unzip(file_names,'/content/yolov5-tflite/custom_dataset/custom_dataset/val/images')\n"
      ],
      "metadata": {
        "id": "60rtknQ9RiD8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cdfae2c-0205-43d6-d14e-558dd70851d3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[원천]bbox(실제도로환경).zip', '[원천]bbox(통제환경).zip', '[원천]keypoint(준통제환경).zip']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "make_yaml = {\n",
        "             \"train\" : \"/content/yolov5-tflite/custom_dataset/custom_dataset/train\",\n",
        "            \"test\": \"/content/yolov5-tflite/custom_dataset/custom_dataset/test\",\n",
        "            \"val\": \"/content/yolov5-tflite/custom_dataset/custom_dataset/val\",\n",
        "\n",
        "             \"nc\" : 4,\n",
        "             \"names\": [\"left_open_eye\",\"left_closed_eye\", \"right_open_eye\",\"right_closed_eye\"]\n",
        "}\n",
        "with open('/content/yolov5-tflite/data/custom_dataset.yaml', 'w') as outfile:\n",
        "    yaml.dump(make_yaml, outfile, default_flow_style=False)"
      ],
      "metadata": {
        "id": "_68rC70FRllS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_names = '/content/gdrive/MyDrive/hyps.zip'\n",
        "unzip(file_names,'/content/yolov5-tflite/data')"
      ],
      "metadata": {
        "id": "-EtU9IIXuc2I"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/yolov5-tflite/w+labels.txt','w') as f:\n",
        "  f.write('left_open_eye\\n')\n",
        "  f.write('left_closed_eye\\n')\n",
        "  f.write('right_open_eye\\n')\n",
        "  f.write('right_closed_eye')"
      ],
      "metadata": {
        "id": "l6gxg10cuq-_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 320 --cfg yolov5s.yaml --hyp /content/yolov5-tflite/data/hyp.scratch-high.yaml --batch 32 --epochs 1 --data /content/yolov5-tflite/data/custom_dataset.yaml --weights yolov5s.pt --workers 24"
      ],
      "metadata": {
        "id": "vQIDK9j8Rmn4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6951413a-2268-4587-f6fe-ecd6c671f5df"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=yolov5s.yaml, data=/content/yolov5-tflite/data/custom_dataset.yaml, hyp=/content/yolov5-tflite/data/hyp.scratch-high.yaml, epochs=1, batch_size=32, imgsz=320, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=24, entity=None, project=runs/train, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1, freeze=0, patience=100\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/hansheng0512/yolov5-tflite ✅\n",
            "YOLOv5 🚀 52d4d5f torch 1.10.0+cu111 CUDA:0 (Tesla P100-PCIE-16GB, 16280.875MB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.1, copy_paste=0.1\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 31.4MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
            "  9                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 283 layers, 7071633 parameters, 7071633 gradients, 16.4 GFLOPs\n",
            "\n",
            "Transferred 308/362 items from yolov5s.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 59 weight, 62 weight (no decay), 62 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/yolov5-tflite/custom_dataset/custom_dataset/train/labels/001_G1' images and labels...286116 found, 840 missing, 0 empty, 3 corrupted: 100% 286958/286958 [01:58<00:00, 2425.48it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/yolov5-tflite/custom_dataset/custom_dataset/train/images/2.승용/R_540_40_M/R_540_40_M_15_M0_G1_C0_11.jpg: negative labels\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/yolov5-tflite/custom_dataset/custom_dataset/train/images/3.택시/R_314_60_M/R_314_60_M_09_M0_G1_C0_09.jpg: cannot identify image file '/content/yolov5-tflite/custom_dataset/custom_dataset/train/images/3.택시/R_314_60_M/R_314_60_M_09_M0_G1_C0_09.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/yolov5-tflite/custom_dataset/custom_dataset/train/images/3.택시/R_314_60_M/R_314_60_M_12_M0_G1_C0_09.jpg: cannot identify image file '/content/yolov5-tflite/custom_dataset/custom_dataset/train/images/3.택시/R_314_60_M/R_314_60_M_12_M0_G1_C0_09.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: corrupt JPEG restored and saved /content/yolov5-tflite/custom_dataset/custom_dataset/train/images/3.택시/R_314_60_M/R_314_60_M_15_M0_G1_C0_06.jpg\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov5-tflite/custom_dataset/custom_dataset/train/labels/001_G1.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5-tflite/custom_dataset/custom_dataset/val/labels/045_G1' images and labels...12113 found, 450 missing, 0 empty, 0 corrupted: 100% 12563/12563 [00:07<00:00, 1689.68it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov5-tflite/custom_dataset/custom_dataset/val/labels/045_G1.cache\n",
            "Plotting labels... \n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 2.71, Best Possible Recall (BPR) = 0.9725. Attempting to improve anchors, please wait...\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mWARNING: Extremely small objects found. 14616 of 572230 labels are < 3 pixels in size.\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 557880 points...\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 0.9749 best possible recall, 8.77 anchors past thr\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=320, metric_all=0.689/0.894-mean/best, past_thr=0.707-mean: 9,5,  13,6,  12,8,  16,7,  15,10,  18,9,  20,10,  18,11,  22,12\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.9188: 100% 1000/1000 [01:30<00:00, 11.03it/s]\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 0.9749 best possible recall, 8.77 anchors past thr\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=320, metric_all=0.696/0.896-mean/best, past_thr=0.714-mean: 10,5,  14,6,  12,8,  15,7,  14,10,  18,9,  18,11,  20,10,  21,12\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
            "\n",
            "Image sizes 320 train, 320 val\n",
            "Using 4 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       0/0     1.82G    0.1232   0.01022   0.02246       121       320:  21% 1849/8968 [19:04<59:18,  2.00it/s]  Corrupt JPEG data: premature end of data segment\n",
            "       0/0     1.82G    0.1108   0.01039   0.02194        96       320:  33% 2916/8968 [30:07<44:43,  2.26it/s]Corrupt JPEG data: premature end of data segment\n",
            "       0/0     1.82G   0.08952   0.01029   0.02125        98       320:  81% 7264/8968 [1:14:45<12:07,  2.34it/s]Corrupt JPEG data: premature end of data segment\n",
            "       0/0     1.82G   0.08801   0.01025   0.02079       110       320:  88% 7923/8968 [1:21:34<08:35,  2.03it/s]Corrupt JPEG data: premature end of data segment\n",
            "       0/0     1.82G   0.08582   0.01022   0.01981        21       320: 100% 8968/8968 [1:32:21<00:00,  1.62it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 197/197 [01:05<00:00,  3.00it/s]\n",
            "                 all      12563      24226      0.641      0.733       0.68       0.33\n",
            "\n",
            "1 epochs completed in 1.558 hours.\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 14.3MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 14.3MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model Summary: 224 layers, 7062001 parameters, 0 gradients, 16.4 GFLOPs\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 197/197 [01:07<00:00,  2.91it/s]\n",
            "                 all      12563      24226      0.641      0.733       0.68       0.33\n",
            "       left_open_eye      12563       8669      0.743      0.965      0.915      0.485\n",
            "     left_closed_eye      12563       3444      0.539      0.605      0.507      0.207\n",
            "      right_open_eye      12563       8292      0.743      0.929      0.901      0.458\n",
            "    right_closed_eye      12563       3821      0.539      0.433      0.397      0.169\n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = '/content/gdrive/MyDrive/result/fifth'\n",
        "save_file_path = '/content/yolov5-tflite/runs/train'\n",
        "\n",
        "shutil.move(save_file_path, save_path)"
      ],
      "metadata": {
        "id": "ed6OcgYpR7WX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3a145b15-017c-46d2-ddf2-3f60bfae8d8b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/MyDrive/result/fifth'"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --source /content/yolov5-tflite/data/detect/images/Q_001_30_M_01_M0_G0_C0 --weights /content/gdrive/MyDrive/result/fifth/exp/weights/best.pt --conf 0.25 --name exp"
      ],
      "metadata": {
        "id": "4ZlUjqNWR1K1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d585377-be77-46c9-e68c-8a334ccdd819"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/gdrive/MyDrive/result/fifth/exp/weights/best.pt'], source=/content/yolov5-tflite/data/detect/images/Q_001_30_M_01_M0_G0_C0, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False\n",
            "YOLOv5 🚀 52d4d5f torch 1.10.0+cu111 CUDA:0 (Tesla P100-PCIE-16GB, 16280.875MB)\n",
            "\n",
            "Fusing layers... \n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 224 layers, 7062001 parameters, 0 gradients, 16.4 GFLOPs\n",
            "image 1/25 /content/yolov5-tflite/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_01.jpg: 640x384 1 left_open_eye, 1 right_closed_eye, Done. (0.012s)\n",
            "image 2/25 /content/yolov5-tflite/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_02.jpg: 640x384 1 left_open_eye, 1 left_closed_eye, 1 right_closed_eye, Done. (0.008s)\n",
            "image 3/25 /content/yolov5-tflite/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_03.jpg: 640x384 1 left_open_eye, 1 left_closed_eye, 1 right_open_eye, 1 right_closed_eye, Done. (0.008s)\n",
            "image 4/25 /content/yolov5-tflite/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_04.jpg: 640x384 1 left_closed_eye, 1 right_open_eye, 2 right_closed_eyes, Done. (0.008s)\n",
            "image 5/25 /content/yolov5-tflite/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_05.jpg: 640x384 2 left_closed_eyes, 2 right_closed_eyes, Done. (0.008s)\n",
            "image 6/25 /content/yolov5-tflite/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_06.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.008s)\n",
            "image 7/25 /content/yolov5-tflite/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_07.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.008s)\n",
            "image 8/25 /content/yolov5-tflite/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_08.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.008s)\n",
            "image 9/25 /content/yolov5-tflite/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_09.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.008s)\n",
            "image 10/25 /content/yolov5-tflite/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_10.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.008s)\n",
            "image 11/25 /content/yolov5-tflite/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_11.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.008s)\n",
            "image 12/25 /content/yolov5-tflite/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_12.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.008s)\n",
            "image 13/25 /content/yolov5-tflite/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_13.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.008s)\n",
            "image 14/25 /content/yolov5-tflite/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_14.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.008s)\n",
            "image 15/25 /content/yolov5-tflite/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_15.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.008s)\n",
            "image 16/25 /content/yolov5-tflite/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_16.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.008s)\n",
            "image 17/25 /content/yolov5-tflite/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_17.jpg: 640x384 1 left_open_eye, 1 left_closed_eye, 1 right_open_eye, Done. (0.008s)\n",
            "image 18/25 /content/yolov5-tflite/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_18.jpg: 640x384 1 left_open_eye, 1 left_closed_eye, 1 right_open_eye, Done. (0.008s)\n",
            "image 19/25 /content/yolov5-tflite/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_19.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.008s)\n",
            "image 20/25 /content/yolov5-tflite/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_20.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.008s)\n",
            "image 21/25 /content/yolov5-tflite/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_21.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.008s)\n",
            "image 22/25 /content/yolov5-tflite/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_22.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.008s)\n",
            "image 23/25 /content/yolov5-tflite/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_23.jpg: 640x384 1 left_open_eye, 1 left_closed_eye, 1 right_open_eye, Done. (0.009s)\n",
            "image 24/25 /content/yolov5-tflite/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_24.jpg: 640x384 1 left_open_eye, 1 right_open_eye, Done. (0.008s)\n",
            "image 25/25 /content/yolov5-tflite/data/detect/images/Q_001_30_M_01_M0_G0_C0/Q_001_30_M_01_M0_G0_C0_25.jpg: 640x384 2 left_closed_eyes, 1 right_open_eye, 1 right_closed_eye, Done. (0.008s)\n",
            "Speed: 0.4ms pre-process, 8.1ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!python models/tf.py --weights /content/gdrive/MyDrive/result/fifth/exp/weights/best.pt"
      ],
      "metadata": {
        "id": "szoE0v3cqeRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = '/content/gdrive/MyDrive/result/fifth/detect'\n",
        "save_file_path = '/content/yolov5-tflite/runs/detect/exp'\n",
        "\n",
        "shutil.move(save_file_path, save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "a2WJCeo8XdMU",
        "outputId": "52d59cc1-c22b-4932-e182-0dda92a3654a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/MyDrive/result/fifth/detect'"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python export.py --weights /content/gdrive/MyDrive/result/fifth/exp/weights/best.pt --include tflite --tf-nms --agnostic-nms"
      ],
      "metadata": {
        "id": "48eKwFheR8pF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2722bdfc-d882-42c3-dabc-dca48d47225e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mexport: \u001b[0mdata=data/coco128.yaml, weights=/content/gdrive/MyDrive/result/fifth/exp/weights/best.pt, imgsz=[640, 640], batch_size=1, device=cpu, half=False, inplace=False, train=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=13, tf_nms=True, agnostic_nms=True, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['tflite']\n",
            "YOLOv5 🚀 52d4d5f torch 1.10.0+cu111 CPU\n",
            "\n",
            "Fusing layers... \n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 224 layers, 7062001 parameters, 0 gradients, 16.4 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from /content/gdrive/MyDrive/result/fifth/exp/weights/best.pt (14.3 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow saved_model:\u001b[0m starting export with tensorflow 2.8.0...\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
            "2022-03-04 13:51:11.179182: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  1    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
            "  9                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512], [640, 640]]\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(1, 640, 640, 3)]   0           []                               \n",
            "                                                                                                  \n",
            " tf_focus (TFFocus)             (1, 320, 320, 32)    3488        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " tf_conv_1 (TFConv)             (1, 160, 160, 64)    18496       ['tf_focus[0][0]']               \n",
            "                                                                                                  \n",
            " tfc3 (TFC3)                    (1, 160, 160, 64)    18624       ['tf_conv_1[0][0]']              \n",
            "                                                                                                  \n",
            " tf_conv_7 (TFConv)             (1, 80, 80, 128)     73856       ['tfc3[0][0]']                   \n",
            "                                                                                                  \n",
            " tfc3_1 (TFC3)                  (1, 80, 80, 128)     156288      ['tf_conv_7[0][0]']              \n",
            "                                                                                                  \n",
            " tf_conv_17 (TFConv)            (1, 40, 40, 256)     295168      ['tfc3_1[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_2 (TFC3)                  (1, 40, 40, 256)     623872      ['tf_conv_17[0][0]']             \n",
            "                                                                                                  \n",
            " tf_conv_27 (TFConv)            (1, 20, 20, 512)     1180160     ['tfc3_2[0][0]']                 \n",
            "                                                                                                  \n",
            " tfspp (TFSPP)                  (1, 20, 20, 512)     656128      ['tf_conv_27[0][0]']             \n",
            "                                                                                                  \n",
            " tfc3_3 (TFC3)                  (1, 20, 20, 512)     1181184     ['tfspp[0][0]']                  \n",
            "                                                                                                  \n",
            " tf_conv_35 (TFConv)            (1, 20, 20, 256)     131328      ['tfc3_3[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_upsample (TFUpsample)       (1, 40, 40, 256)     0           ['tf_conv_35[0][0]']             \n",
            "                                                                                                  \n",
            " tf_concat (TFConcat)           (1, 40, 40, 512)     0           ['tf_upsample[0][0]',            \n",
            "                                                                  'tfc3_2[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_4 (TFC3)                  (1, 40, 40, 256)     361216      ['tf_concat[0][0]']              \n",
            "                                                                                                  \n",
            " tf_conv_41 (TFConv)            (1, 40, 40, 128)     32896       ['tfc3_4[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_upsample_1 (TFUpsample)     (1, 80, 80, 128)     0           ['tf_conv_41[0][0]']             \n",
            "                                                                                                  \n",
            " tf_concat_1 (TFConcat)         (1, 80, 80, 256)     0           ['tf_upsample_1[0][0]',          \n",
            "                                                                  'tfc3_1[0][0]']                 \n",
            "                                                                                                  \n",
            " tfc3_5 (TFC3)                  (1, 80, 80, 128)     90496       ['tf_concat_1[0][0]']            \n",
            "                                                                                                  \n",
            " tf_conv_47 (TFConv)            (1, 40, 40, 128)     147584      ['tfc3_5[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_concat_2 (TFConcat)         (1, 40, 40, 256)     0           ['tf_conv_47[0][0]',             \n",
            "                                                                  'tf_conv_41[0][0]']             \n",
            "                                                                                                  \n",
            " tfc3_6 (TFC3)                  (1, 40, 40, 256)     295680      ['tf_concat_2[0][0]']            \n",
            "                                                                                                  \n",
            " tf_conv_53 (TFConv)            (1, 20, 20, 256)     590080      ['tfc3_6[0][0]']                 \n",
            "                                                                                                  \n",
            " tf_concat_3 (TFConcat)         (1, 20, 20, 512)     0           ['tf_conv_53[0][0]',             \n",
            "                                                                  'tf_conv_35[0][0]']             \n",
            "                                                                                                  \n",
            " tfc3_7 (TFC3)                  (1, 20, 20, 512)     1181184     ['tf_concat_3[0][0]']            \n",
            "                                                                                                  \n",
            " tf_detect (TFDetect)           ((1, 25200, 9),      24273       ['tfc3_5[0][0]',                 \n",
            "                                 [(1, 3, 6400, 9),                'tfc3_6[0][0]',                 \n",
            "                                 (1, 3, 1600, 9),                 'tfc3_7[0][0]']                 \n",
            "                                 (1, 3, 400, 9)])                                                 \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (1, 25200, 4)       0           ['tf_detect[0][0]']              \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " tf.split (TFOpLambda)          [(1, 25200, 1),      0           ['tf.__operators__.getitem[0][0]'\n",
            "                                 (1, 25200, 1),                  ]                                \n",
            "                                 (1, 25200, 1),                                                   \n",
            "                                 (1, 25200, 1)]                                                   \n",
            "                                                                                                  \n",
            " tf.math.truediv_1 (TFOpLambda)  (1, 25200, 1)       0           ['tf.split[0][3]']               \n",
            "                                                                                                  \n",
            " tf.math.truediv (TFOpLambda)   (1, 25200, 1)        0           ['tf.split[0][2]']               \n",
            "                                                                                                  \n",
            " tf.math.truediv_3 (TFOpLambda)  (1, 25200, 1)       0           ['tf.split[0][3]']               \n",
            "                                                                                                  \n",
            " tf.math.truediv_2 (TFOpLambda)  (1, 25200, 1)       0           ['tf.split[0][2]']               \n",
            "                                                                                                  \n",
            " tf.math.subtract_1 (TFOpLambda  (1, 25200, 1)       0           ['tf.split[0][1]',               \n",
            " )                                                                'tf.math.truediv_1[0][0]']      \n",
            "                                                                                                  \n",
            " tf.math.subtract (TFOpLambda)  (1, 25200, 1)        0           ['tf.split[0][0]',               \n",
            "                                                                  'tf.math.truediv[0][0]']        \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TFOpLa  (1, 25200, 1)       0           ['tf.split[0][1]',               \n",
            " mbda)                                                            'tf.math.truediv_3[0][0]']      \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  (1, 25200, 1)       0           ['tf.split[0][0]',               \n",
            " da)                                                              'tf.math.truediv_2[0][0]']      \n",
            "                                                                                                  \n",
            " tf.clip_by_value_1 (TFOpLambda  (1, 25200, 1)       0           ['tf.math.subtract_1[0][0]']     \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.clip_by_value (TFOpLambda)  (1, 25200, 1)        0           ['tf.math.subtract[0][0]']       \n",
            "                                                                                                  \n",
            " tf.clip_by_value_3 (TFOpLambda  (1, 25200, 1)       0           ['tf.__operators__.add_1[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.clip_by_value_2 (TFOpLambda  (1, 25200, 1)       0           ['tf.__operators__.add[0][0]']   \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.concat (TFOpLambda)         (1, 25200, 4)        0           ['tf.clip_by_value_1[0][0]',     \n",
            "                                                                  'tf.clip_by_value[0][0]',       \n",
            "                                                                  'tf.clip_by_value_3[0][0]',     \n",
            "                                                                  'tf.clip_by_value_2[0][0]']     \n",
            "                                                                                                  \n",
            " tf.expand_dims (TFOpLambda)    (1, 25200, 1, 4)     0           ['tf.concat[0][0]']              \n",
            "                                                                                                  \n",
            " tf.compat.v1.squeeze (TFOpLamb  (25200, 4)          0           ['tf.expand_dims[0][0]']         \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1 (Sl  (25200,)            0           ['tf.compat.v1.squeeze[0][0]']   \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.math.greater (TFOpLambda)   (25200,)             0           ['tf.__operators__.getitem_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.where (TFOpLambda)          (None, 1)            0           ['tf.math.greater[0][0]']        \n",
            "                                                                                                  \n",
            " tf.compat.v1.gather (TFOpLambd  (None, 1, 4)        0           ['tf.compat.v1.squeeze[0][0]',   \n",
            " a)                                                               'tf.where[0][0]']               \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_2 (Sl  (None, 4)           0           ['tf.compat.v1.gather[0][0]']    \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.compat.v1.squeeze_1 (TFOpLa  (25200, 9)          0           ['tf_detect[0][0]']              \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_4 (Sl  (None,)             0           ['tf.__operators__.getitem_2[0][0\n",
            " icingOpLambda)                                                  ]']                              \n",
            "                                                                                                  \n",
            " tf.compat.v1.gather_1 (TFOpLam  (None, 1, 9)        0           ['tf.compat.v1.squeeze_1[0][0]', \n",
            " bda)                                                             'tf.where[0][0]']               \n",
            "                                                                                                  \n",
            " tf.math.less (TFOpLambda)      (None,)              0           ['tf.__operators__.getitem_4[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_3 (Sl  (None, 9)           0           ['tf.compat.v1.gather_1[0][0]']  \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.where_1 (TFOpLambda)        (None, 1)            0           ['tf.math.less[0][0]']           \n",
            "                                                                                                  \n",
            " tf.compat.v1.gather_3 (TFOpLam  (None, 1, 9)        0           ['tf.__operators__.getitem_3[0][0\n",
            " bda)                                                            ]',                              \n",
            "                                                                  'tf.where_1[0][0]']             \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_6 (Sl  (None, 9)           0           ['tf.compat.v1.gather_3[0][0]']  \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_7 (Sl  (None, 4)           0           ['tf.__operators__.getitem_6[0][0\n",
            " icingOpLambda)                                                  ]']                              \n",
            "                                                                                                  \n",
            " tf.split_1 (TFOpLambda)        [(None, 1),          0           ['tf.__operators__.getitem_7[0][0\n",
            "                                 (None, 1),                      ]']                              \n",
            "                                 (None, 1),                                                       \n",
            "                                 (None, 1)]                                                       \n",
            "                                                                                                  \n",
            " tf.math.truediv_5 (TFOpLambda)  (None, 1)           0           ['tf.split_1[0][3]']             \n",
            "                                                                                                  \n",
            " tf.math.truediv_4 (TFOpLambda)  (None, 1)           0           ['tf.split_1[0][2]']             \n",
            "                                                                                                  \n",
            " tf.math.truediv_7 (TFOpLambda)  (None, 1)           0           ['tf.split_1[0][3]']             \n",
            "                                                                                                  \n",
            " tf.math.truediv_6 (TFOpLambda)  (None, 1)           0           ['tf.split_1[0][2]']             \n",
            "                                                                                                  \n",
            " tf.math.subtract_3 (TFOpLambda  (None, 1)           0           ['tf.split_1[0][1]',             \n",
            " )                                                                'tf.math.truediv_5[0][0]']      \n",
            "                                                                                                  \n",
            " tf.math.subtract_2 (TFOpLambda  (None, 1)           0           ['tf.split_1[0][0]',             \n",
            " )                                                                'tf.math.truediv_4[0][0]']      \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TFOpLa  (None, 1)           0           ['tf.split_1[0][1]',             \n",
            " mbda)                                                            'tf.math.truediv_7[0][0]']      \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TFOpLa  (None, 1)           0           ['tf.split_1[0][0]',             \n",
            " mbda)                                                            'tf.math.truediv_6[0][0]']      \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_8 (Sl  (None, 1)           0           ['tf.__operators__.getitem_6[0][0\n",
            " icingOpLambda)                                                  ]']                              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_9 (Sl  (None, 4)           0           ['tf.__operators__.getitem_6[0][0\n",
            " icingOpLambda)                                                  ]']                              \n",
            "                                                                                                  \n",
            " tf.clip_by_value_5 (TFOpLambda  (None, 1)           0           ['tf.math.subtract_3[0][0]']     \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.clip_by_value_4 (TFOpLambda  (None, 1)           0           ['tf.math.subtract_2[0][0]']     \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.clip_by_value_7 (TFOpLambda  (None, 1)           0           ['tf.__operators__.add_3[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.clip_by_value_6 (TFOpLambda  (None, 1)           0           ['tf.__operators__.add_2[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.math.multiply (TFOpLambda)  (None, 4)            0           ['tf.__operators__.getitem_8[0][0\n",
            "                                                                 ]',                              \n",
            "                                                                  'tf.__operators__.getitem_9[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.concat_1 (TFOpLambda)       (None, 4)            0           ['tf.clip_by_value_5[0][0]',     \n",
            "                                                                  'tf.clip_by_value_4[0][0]',     \n",
            "                                                                  'tf.clip_by_value_7[0][0]',     \n",
            "                                                                  'tf.clip_by_value_6[0][0]']     \n",
            "                                                                                                  \n",
            " tf.math.reduce_max (TFOpLambda  (None,)             0           ['tf.math.multiply[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.image.non_max_suppression (  (None,)             0           ['tf.concat_1[0][0]',            \n",
            " TFOpLambda)                                                      'tf.math.reduce_max[0][0]']     \n",
            "                                                                                                  \n",
            " tf.math.argmax (TFOpLambda)    (None,)              0           ['tf.math.multiply[0][0]']       \n",
            "                                                                                                  \n",
            " tf.compat.v1.gather_6 (TFOpLam  (None,)             0           ['tf.math.argmax[0][0]',         \n",
            " bda)                                                             'tf.image.non_max_suppression[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " tf.compat.v1.gather_5 (TFOpLam  (None,)             0           ['tf.math.reduce_max[0][0]',     \n",
            " bda)                                                             'tf.image.non_max_suppression[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " tf.compat.v1.gather_4 (TFOpLam  (None, 4)           0           ['tf.concat_1[0][0]',            \n",
            " bda)                                                             'tf.image.non_max_suppression[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " tf.reshape_1 (TFOpLambda)      (1, None)            0           ['tf.compat.v1.gather_6[0][0]']  \n",
            "                                                                                                  \n",
            " tf.reshape (TFOpLambda)        (1, None)            0           ['tf.compat.v1.gather_5[0][0]']  \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape (TFOpLambda  (1,)                0           ['tf.image.non_max_suppression[0]\n",
            " )                                                               [0]']                            \n",
            "                                                                                                  \n",
            " tf.expand_dims_1 (TFOpLambda)  (1, None, 4)         0           ['tf.compat.v1.gather_4[0][0]']  \n",
            "                                                                                                  \n",
            " tf.cast_1 (TFOpLambda)         (1, None)            0           ['tf.reshape_1[0][0]']           \n",
            "                                                                                                  \n",
            " tf.cast (TFOpLambda)           (1, None)            0           ['tf.reshape[0][0]']             \n",
            "                                                                                                  \n",
            " tf.cast_2 (TFOpLambda)         (1,)                 0           ['tf.compat.v1.shape[0][0]']     \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,062,001\n",
            "Trainable params: 0\n",
            "Non-trainable params: 7,062,001\n",
            "__________________________________________________________________________________________________\n",
            "Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "2022-03-04 13:51:19.770871: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "Found untraced functions such as tf_conv_layer_call_fn, tf_conv_layer_call_and_return_conditional_losses, tf_conv_2_layer_call_fn, tf_conv_2_layer_call_and_return_conditional_losses, tf_conv_3_layer_call_fn while saving (showing 5 of 220). These functions will not be directly callable after loading.\n",
            "Assets written to: /content/gdrive/MyDrive/result/fifth/exp/weights/best_saved_model/assets\n",
            "\u001b[34m\u001b[1mTensorFlow saved_model:\u001b[0m export success, saved as /content/gdrive/MyDrive/result/fifth/exp/weights/best_saved_model (240.1 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.8.0...\n",
            "Found untraced functions such as tf_conv_layer_call_fn, tf_conv_layer_call_and_return_conditional_losses, tf_conv_2_layer_call_fn, tf_conv_2_layer_call_and_return_conditional_losses, tf_conv_3_layer_call_fn while saving (showing 5 of 220). These functions will not be directly callable after loading.\n",
            "Assets written to: /tmp/tmpg31zgntx/assets\n",
            "2022-03-04 13:52:43.226041: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
            "2022-03-04 13:52:43.226099: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
            "Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success, saved as /content/gdrive/MyDrive/result/fifth/exp/weights/best-fp16.tflite (14.3 MB)\n",
            "\n",
            "Export complete (99.85s)\n",
            "Results saved to \u001b[1m/content/gdrive/MyDrive/result/fifth/exp/weights\u001b[0m\n",
            "Visualize with https://netron.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tflite-support"
      ],
      "metadata": {
        "id": "QY0nA4CkNU6H",
        "outputId": "2d4ff683-2950-4929-8f63-e0184b313f04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tflite-support\n",
            "  Downloading tflite_support-0.3.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 40.0 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 19.0 MB/s eta 0:00:01\r\u001b[K     |█                               | 30 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 61 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 92 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 122 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████                            | 133 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 153 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 163 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 174 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 184 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 194 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████                          | 204 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 215 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 225 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████                         | 235 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 245 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 256 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 266 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 276 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 286 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 296 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 307 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 317 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 327 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 337 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 348 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 358 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 368 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 378 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 389 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 399 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 409 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 419 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 430 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 440 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 450 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 460 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 471 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 481 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 491 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 501 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 512 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 522 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 532 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 542 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 552 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 563 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 573 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 583 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 593 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 604 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 614 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 624 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 634 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 645 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 655 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 665 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 675 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 686 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 696 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 706 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 716 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 727 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 737 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 747 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 757 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 768 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 778 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 788 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 798 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 808 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 819 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 829 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 839 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 849 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 860 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 870 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 880 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 890 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 901 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 911 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 921 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 931 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 942 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 952 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 962 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 972 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 983 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 993 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.0 MB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.0 MB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.0 MB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.0 MB 7.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.0 MB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1 MB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.1 MB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.1 MB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tflite-support) (1.21.5)\n",
            "Collecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting pybind11>=2.6.0\n",
            "  Downloading pybind11-2.9.1-py2.py3-none-any.whl (211 kB)\n",
            "\u001b[K     |████████████████████████████████| 211 kB 78.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tflite-support) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.7.0->tflite-support) (1.15.0)\n",
            "Installing collected packages: pybind11, flatbuffers, tflite-support\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\u001b[0m\n",
            "Successfully installed flatbuffers-1.12 pybind11-2.9.1 tflite-support-0.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python metadata_writer_v1.py --model_file /content/gdrive/MyDrive/result/fifth/exp/weights/best-fp16.tflite --label_file /content/yolov5-tflite/w+labels.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDtsW1mxnbb2",
        "outputId": "c8fc0b32-1f0c-496c-aa0a-4a2b39a564b1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metadata populated:\n",
            "{\n",
            "  \"name\": \"ObjectDetector\",\n",
            "  \"description\": \"Identify which of a known set of objects might be present and provide information about their positions within the given image or a video stream.\",\n",
            "  \"subgraph_metadata\": [\n",
            "    {\n",
            "      \"input_tensor_metadata\": [\n",
            "        {\n",
            "          \"name\": \"image\",\n",
            "          \"description\": \"Input image to be detected.\",\n",
            "          \"content\": {\n",
            "            \"content_properties_type\": \"ImageProperties\",\n",
            "            \"content_properties\": {\n",
            "              \"color_space\": \"RGB\"\n",
            "            }\n",
            "          },\n",
            "          \"process_units\": [\n",
            "            {\n",
            "              \"options_type\": \"NormalizationOptions\",\n",
            "              \"options\": {\n",
            "                \"mean\": [\n",
            "                  127.5\n",
            "                ],\n",
            "                \"std\": [\n",
            "                  127.5\n",
            "                ]\n",
            "              }\n",
            "            }\n",
            "          ],\n",
            "          \"stats\": {\n",
            "            \"max\": [\n",
            "              1.0\n",
            "            ],\n",
            "            \"min\": [\n",
            "              -1.0\n",
            "            ]\n",
            "          }\n",
            "        }\n",
            "      ],\n",
            "      \"output_tensor_metadata\": [\n",
            "        {\n",
            "          \"name\": \"score\",\n",
            "          \"description\": \"The scores of the detected boxes.\",\n",
            "          \"content\": {\n",
            "            \"content_properties_type\": \"FeatureProperties\",\n",
            "            \"content_properties\": {\n",
            "            },\n",
            "            \"range\": {\n",
            "              \"min\": 2,\n",
            "              \"max\": 2\n",
            "            }\n",
            "          },\n",
            "          \"stats\": {\n",
            "          }\n",
            "        },\n",
            "        {\n",
            "          \"name\": \"location\",\n",
            "          \"description\": \"The locations of the detected boxes.\",\n",
            "          \"content\": {\n",
            "            \"content_properties_type\": \"BoundingBoxProperties\",\n",
            "            \"content_properties\": {\n",
            "              \"index\": [\n",
            "                1,\n",
            "                0,\n",
            "                3,\n",
            "                2\n",
            "              ],\n",
            "              \"type\": \"BOUNDARIES\"\n",
            "            },\n",
            "            \"range\": {\n",
            "              \"min\": 2,\n",
            "              \"max\": 2\n",
            "            }\n",
            "          },\n",
            "          \"stats\": {\n",
            "          }\n",
            "        },\n",
            "        {\n",
            "          \"name\": \"number of detections\",\n",
            "          \"description\": \"The number of the detected boxes.\",\n",
            "          \"content\": {\n",
            "            \"content_properties_type\": \"FeatureProperties\",\n",
            "            \"content_properties\": {\n",
            "            }\n",
            "          },\n",
            "          \"stats\": {\n",
            "          }\n",
            "        },\n",
            "        {\n",
            "          \"name\": \"category\",\n",
            "          \"description\": \"The categories of the detected boxes.\",\n",
            "          \"content\": {\n",
            "            \"content_properties_type\": \"FeatureProperties\",\n",
            "            \"content_properties\": {\n",
            "            },\n",
            "            \"range\": {\n",
            "              \"min\": 2,\n",
            "              \"max\": 2\n",
            "            }\n",
            "          },\n",
            "          \"stats\": {\n",
            "          },\n",
            "          \"associated_files\": [\n",
            "            {\n",
            "              \"name\": \"w+labels.txt\",\n",
            "              \"description\": \"Labels for categories that the model can recognize.\",\n",
            "              \"type\": \"TENSOR_VALUE_LABELS\"\n",
            "            }\n",
            "          ]\n",
            "        }\n",
            "      ],\n",
            "      \"output_tensor_groups\": [\n",
            "        {\n",
            "          \"name\": \"detection_result\",\n",
            "          \"tensor_names\": [\n",
            "            \"location\",\n",
            "            \"category\",\n",
            "            \"score\"\n",
            "          ]\n",
            "        }\n",
            "      ]\n",
            "    }\n",
            "  ],\n",
            "  \"min_parser_version\": \"1.2.0\"\n",
            "}\n",
            "\n",
            "Associated file(s) populated:\n",
            "['w+labels.txt']\n",
            "Success!\n",
            "Metadata and the label file have been written into best-fp16-metadata-v1.tflite.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = '/content/gdrive/MyDrive/result/fifth/exp/weights'\n",
        "save_file_path = '/content/yolov5-tflite/best-fp16-metadata-v1.tflite'\n",
        "\n",
        "shutil.move(save_file_path, save_path)"
      ],
      "metadata": {
        "id": "6MJY-sEFOuW3",
        "outputId": "877b8a29-e5ed-4a7e-8350-de0304c28c70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/MyDrive/result/fifth/exp/weights/best-fp16-metadata-v1.tflite'"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}